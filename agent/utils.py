import feedparser
import ssl
import socket
import random
import re
from urllib.parse import urlparse

# ==========================================
#  1. THE "RSS BACKDOOR" SEARCH (Real & Unblockable)
# ==========================================
import feedparser # Make sure this is imported at the top

def search_web_for_scholarships(query):
    """
    Uses Google News RSS to find Government & University specific results.
    """
    print(f"ðŸ“¡ Rudra is scanning Google News feeds for: '{query}'...")
    
    # 1. BUILD THE SMART QUERY
    # We combine the user's topic with site filters to prioritize official sources
    official_query = f"{query} scholarship (site:.gov.in OR site:.nic.in OR site:.edu.in OR application)"
    clean_query = official_query.replace(" ", "+")
    
    # 2. CONSTRUCT THE URL (Do this ONCE)
    rss_url = f"https://news.google.com/rss/search?q={clean_query}&hl=en-IN&gl=IN&ceid=IN:en"
    
    results = []

    try:
        # 3. FETCH DATA
        print(f"ðŸ”Ž Fetching: {rss_url}") # Debug print to see what URL is actually used
        feed = feedparser.parse(rss_url)

        if feed.entries:
            for entry in feed.entries[:8]:
                results.append({
                    'title': entry.title,
                    'url': entry.link,
                    'source': 'Government/Official News' # Updated label
                })
        else:
            print("âš ï¸ No live official news found. Checking fallback...")

    except Exception as e:
        print(f"âŒ RSS Error: {e}")

    # ==========================================
    #  4. FAIL-SAFE (The Safety Net)
    # ==========================================
    if not results:
        print(f"âš ï¸ Live feed empty. Switching to SMART SIMULATION for '{query}'.")
        return get_simulation_data(query)
        
    print(f"âœ… Found {len(results)} REAL live results.")
    return results
def get_simulation_data(query):
    """
    Backup generator that creates realistic links based on context.
    Only runs if the Live RSS returns 0 results.
    """
    query = query.lower()
    
    # Context: Tech/Engineering
    if any(x in query for x in ['python', 'code', 'tech', 'engineer', 'data']):
        return [
            {'title': 'Google Generation Scholarship (APAC)', 'url': 'https://buildyourfuture.withgoogle.com/scholarships', 'source': 'Google Careers'},
            {'title': 'AICTE Pragati Scholarship for Girls', 'url': 'https://www.aicte-india.org/schemes', 'source': 'AICTE Official'},
            {'title': 'Python Institute Certified Grant', 'url': 'https://python.org/grants', 'source': 'Open Source Fund'}
        ]
    # Context: Medical
    elif any(x in query for x in ['medical', 'mbbs', 'doctor', 'nurse']):
        return [
            {'title': 'Nationwide MBBS Merit Scholarship', 'url': 'https://scholarships.gov.in', 'source': 'National Portal'},
            {'title': 'Tata Trusts Medical Grants', 'url': 'https://www.tatatrusts.org', 'source': 'Trust Foundation'}
        ]
    # Default
    else:
        return [
            {'title': f'National {query.title()} Scheme', 'url': 'https://scholarships.gov.in', 'source': 'Gov.in'},
            {'title': f'Buddy4Study {query.title()} Search', 'url': 'https://www.buddy4study.com', 'source': 'Partner Portal'}
        ]

# ==========================================
#  3. AUTHENTICITY VERIFICATION
# ==========================================
def verify_url_authenticity(url):
    try:
        domain = urlparse(url).netloc
    except:
        return 0, ["Invalid URL"], ""

    trust_score = 0
    flags = []

    # Trust Whitelist
    trusted_domains = ['.gov.in', '.edu.in', '.ac.in', 'shiksha.com', 'buddy4study.com', 'aicte-india.org', 'google.com', 'tatatrusts.org']
    if any(t in domain for t in trusted_domains):
        trust_score += 50
    
    # SSL Check
    if "https" in url:
        trust_score += 20
    else:
        trust_score -= 20
        flags.append("Not Secure (HTTP)")

    # Scam Keywords
    if any(w in url for w in ["money", "cash", "scam", "free", "lottery"]):
        trust_score = -20
        flags.append("Suspicious Keywords")

    return trust_score, flags, f"Content analysis of {url}"

# ==========================================
#  4. EXTRACTION (Required placeholder)
# ==========================================
def extract_details(text):
    return {"income": "Check Portal", "deadline": "Open"}

# ==========================================
#  5. FETCH RSS (Required placeholder)
# ==========================================
def fetch_rss_feeds():
    # Re-uses the search logic for the news ticker if needed
    return search_web_for_scholarships("general scholarship")[:5]
# agent/utils.py

def analyze_nlp_tone(text):
    """
    Analyzes text for 'Pushy' or 'Aggressive' tones.
    Scammers use psychological pressure to make you act without thinking.
    """
    text = text.lower()
    penalty = 0
    flags = []

    # 1. THE "PUSHY" CHECK (Aggressive Urgency)
    pushy_patterns = [
        "act now", "don't wait", "urgent", "immediate action", 
        "expires in", "last chance", "hurry", "limited spots"
    ]
    
    # Check for excessive exclamation marks (A classic pushy tactic)
    if text.count('!') > 2:
        penalty -= 15
        flags.append("Aggressive Punctuation (!!!)")

    # Check for pushy keywords
    found_pushy = [w for w in pushy_patterns if w in text]
    if found_pushy:
        penalty -= 25
        flags.append(f"Pushy Tone Detected: {', '.join(found_pushy)}")

    # 2. THE "TOO GOOD TO BE TRUE" CHECK (False Guarantees)
    guarantees = ["100% success", "guaranteed", "no selection", "direct entry", "free cash"]
    if any(g in text for g in guarantees):
        penalty -= 30
        flags.append("Unrealistic Guarantees")

    return penalty, flags

def verify_url_authenticity(url, title=""):
    """
    Updated authenticity agent with NLP Tone Analysis.
    """
    try:
        domain = urlparse(url).netloc
    except:
        return 0, ["Invalid URL"], ""

    trust_score = 0
    flags = []

    # --- LAYER 1: WHITELIST ---
    trusted = ['.gov.in', '.edu.in', '.ac.in', 'aicte-india.org']
    if any(t in domain for t in trusted):
        return 100, ["Official Source"], "High Trust"

    # --- LAYER 2: NLP TONE CHECK (The 'Pushy' Check) ---
    # We analyze both the URL and the Title for pushiness
    combined_text = f"{url} {title}"
    nlp_penalty, nlp_flags = analyze_nlp_tone(combined_text)
    
    trust_score += nlp_penalty
    flags.extend(nlp_flags)

    # --- LAYER 3: SECURITY & AGE ---
    if not url.startswith("https"):
        trust_score -= 30
        flags.append("Insecure Connection (No SSL)")

    # (Add your Whois Age logic here as well)

    return max(-100, min(100, trust_score)), flags, "Security Scan Complete"
